{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import system files\n",
    "import sys\n",
    "# !{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the activity dataset\n",
    "df1 = pd.read_csv(\"/Users/whitegg/Documents/GitHub/Project/FinalSemesterProject/ehact_2014.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load respondent dataset\n",
    "df2 = pd.read_csv(\"/Users/whitegg/Documents/GitHub/Project/FinalSemesterProject/ehresp_2014.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weight dataset\n",
    "df3 = pd.read_csv(\"/Users/whitegg/Documents/GitHub/Project/FinalSemesterProject/ehwgts_2014.csv\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter bmi, height and weight\n",
    "df = df2[[\"erbmi\", \"euhgt\", \"euwgt\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the distribution of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the dataset after duplicate removal\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter heights less than 21 and weight less than 5\n",
    "df = df[(df.euhgt > 21) & (df.euwgt > 5)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check resulting dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for na values\n",
    "df.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop na values\n",
    "df = df.dropna(thresh=len(df.columns) // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check result after na was removed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recheck the distribution of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the correlations of the features in the dataset\n",
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Linear Regression to check intercept and coefficient\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df[[\"euhgt\", \"euwgt\"]]\n",
    "y = df[\"erbmi\"]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Check the coefficients\n",
    "print(f\"Intercept: {model.intercept_}\")\n",
    "print(f\"Coefficients: {model.coef_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# List of columns to check for outliers\n",
    "columns = ['erbmi', 'euhgt', 'euwgt']\n",
    "\n",
    "# Create a figure and axis for each boxplot\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    plt.subplot(1, len(columns), i + 1)\n",
    "    sns.boxplot(x=df[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "    plt.xlabel(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#plot histogram to to diplay the distribution of BMI\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['erbmi'], bins=30, kde=True, color='skyblue')\n",
    "plt.title('Distribution of BMI')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig(\"Distribution of BMI\") \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot scatter to to diplay the relationship of Height and BMI\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='euhgt', y='erbmi', data=df, color='blue')\n",
    "plt.title('Height vs BMI')\n",
    "plt.xlabel('Height (in inches)')\n",
    "plt.ylabel('BMI')\n",
    "plt.savefig(\"Height vs BMI\") \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot scatterplot to diplay the relationship of Weight and BMI\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='euwgt', y='erbmi', data=df, color='green')\n",
    "plt.title('Weight vs BMI')\n",
    "plt.xlabel('Weight (in pounds)')\n",
    "plt.ylabel('BMI')\n",
    "plt.savefig(\"Weight vs BMI\") \n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot jointplot to diplay the relationship of Height, Weight and BMI\n",
    "\n",
    "sns.jointplot(x='euhgt', y='euwgt', data=df, kind='scatter', hue='erbmi', palette='coolwarm', height=8)\n",
    "plt.title('Joint Plot of Height and Weight colored by BMI')\n",
    "plt.xlabel('Height (in inches)')\n",
    "plt.ylabel('Weight (in pounds)')\n",
    "plt.savefig(\"Joint Plot of Height and Weight colored by BMI\") \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot pairplot to diplay the relationship of Height, Weight and BMI\n",
    "sns.pairplot(df[['euhgt', 'euwgt', 'erbmi']], kind='reg', diag_kind='kde', height=3)\n",
    "plt.suptitle('Pairwise Relationships', y=1.02)\n",
    "plt.savefig(\"Pairwise Relationships\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the correlation of the features\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.savefig(\"Feature Correlation Matrix\") \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dframe = df.copy()\n",
    "dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Library\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to categorize BMI\n",
    "def categorize_bmi(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif 18.5 <= bmi <= 24.9:\n",
    "        return 'Normal Weight'\n",
    "    elif 25 <= bmi <= 29.9:\n",
    "        return 'Overweight'\n",
    "    elif bmi >= 30:\n",
    "        return 'Obese'\n",
    "    else:\n",
    "        return 'Invalid'\n",
    "\n",
    "# Apply the function to create a new column in the DataFrame\n",
    "df['bmi_category'] = df['erbmi'].apply(categorize_bmi)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "# print(df[['erbmi', 'bmi_category']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bmi_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Normalization of height and weight\n",
    "scaler = StandardScaler()\n",
    "df[['euhgt', 'euwgt']] = scaler.fit_transform(df[['euhgt', 'euwgt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences in each BMI category\n",
    "bmi_counts = df['bmi_category'].value_counts()\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=bmi_counts.index, y=bmi_counts.values, palette='viridis')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution of BMI Categories', fontsize=16)\n",
    "plt.xlabel('BMI Category', fontsize=14)\n",
    "plt.ylabel('Number of Individuals', fontsize=14)\n",
    "plt.savefig(\"Distribution of BMI Categories\") \n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Perform ANOVA on BMI categories\n",
    "model = ols('erbmi ~ C(bmi_category)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# Post-hoc test\n",
    "tukey = pairwise_tukeyhsd(df['erbmi'], df['bmi_category'], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey.plot_simultaneous()\n",
    "plt.title('Tukey HSD Test for Weight across BMI Categories')\n",
    "plt.savefig(\"Tukey HSD Test for Weight across BMI Categories\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Group the data by BMI categories\n",
    "underweight = df[df['bmi_category'] == 'Underweight']['euwgt']\n",
    "normal_weight = df[df['bmi_category'] == 'Normal Weight']['euwgt']\n",
    "overweight = df[df['bmi_category'] == 'Overweight']['euwgt']\n",
    "obese = df[df['bmi_category'] == 'Obese']['euwgt']\n",
    "\n",
    "# Perform ANOVA\n",
    "f_stat, p_value = f_oneway(underweight, normal_weight, overweight, obese)\n",
    "print(f\"F-statistic: {f_stat}, P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "# Model Training and Evaluation\n",
    "\n",
    "X = df[['euhgt', 'euwgt']]\n",
    "y = df['erbmi']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Support Vector Machine': SVR(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MSE': mse\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  R2 = {metrics['R2']}\")\n",
    "    print(f\"  MAE = {metrics['MAE']}\")\n",
    "    print(f\"  RMSE = {metrics['RMSE']}\")\n",
    "    print(f\"  MSE = {metrics['MSE']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Hyperparameter Tuning (Example with Random Forest)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best parameters for Gradient Boosting: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Support Vector Machine': SVR(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df[['euhgt', 'euwgt']]\n",
    "y = df['erbmi']\n",
    "y_category = df['bmi_category']  # Actual BMI categories\n",
    "\n",
    "X_train, X_test, y_train, y_test, y_train_category, y_test_category = train_test_split(X, y, y_category, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize dictionaries to store metrics\n",
    "accuracy_scores = {}\n",
    "precision_scores = {}\n",
    "recall_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Function to categorize BMI\n",
    "def categorize_bmi(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif 18.5 <= bmi < 24.9:\n",
    "        return 'Normal Weight'\n",
    "    elif 25 <= bmi < 29.9:\n",
    "        return 'Overweight'\n",
    "    elif bmi >= 30:\n",
    "        return 'Obese'\n",
    "    else:\n",
    "        return 'Invalid'\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Convert the predicted BMI to categories\n",
    "    y_pred_category = [categorize_bmi(bmi) for bmi in y_pred]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy_scores[name] = accuracy_score(y_test_category, y_pred_category)\n",
    "    precision_scores[name] = precision_score(y_test_category, y_pred_category, average='weighted')\n",
    "    recall_scores[name] = recall_score(y_test_category, y_pred_category, average='weighted')\n",
    "    f1_scores[name] = f1_score(y_test_category, y_pred_category, average='weighted')\n",
    "\n",
    "# Display the results\n",
    "print(\"Model Performance Metrics:\")\n",
    "for name in models.keys():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Accuracy: {accuracy_scores[name]}\")\n",
    "    print(f\"  Precision: {precision_scores[name]}\")\n",
    "    print(f\"  Recall: {recall_scores[name]}\")\n",
    "    print(f\"  F1-Score: {f1_scores[name]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure that BMI categories are correctly assigned\n",
    "df['bmi_category'] = df['erbmi'].apply(categorize_bmi)\n",
    "\n",
    "# Create a DataFrame for the Tukey HSD test\n",
    "data_for_tukey = df[['euwgt', 'bmi_category']]\n",
    "data_for_tukey = data_for_tukey.dropna()  # Drop any missing values if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey = pairwise_tukeyhsd(endog=data_for_tukey['euwgt'],\n",
    "                          groups=data_for_tukey['bmi_category'],\n",
    "                          alpha=0.05)\n",
    "\n",
    "# Print the results\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey.plot_simultaneous()\n",
    "plt.title('Tukey HSD Test for Weight across BMI Categories')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Handle missing and invalid values\n",
    "df = df[(df['euhgt'] > 0) & (df['euwgt'] > 0)]\n",
    "\n",
    "# Features and target\n",
    "X = df[['euhgt', 'euwgt']]\n",
    "y = df['erbmi']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Support Vector Machine': SVR(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    results[name] = mse\n",
    "\n",
    "# Print the results\n",
    "for name, mse in results.items():\n",
    "    print(f\"{name}: MSE = {mse}\")\n",
    "\n",
    "# Find the best model based on MSE\n",
    "best_model_name = min(results, key=results.get)\n",
    "print(f\"Best model: {best_model_name} with MSE = {results[best_model_name]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "# Train and evaluate each model using R², MAE, and RMSE\n",
    "\n",
    "regression_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Store the results\n",
    "    regression_results[name] = {\n",
    "        'R²': r2,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse\n",
    "    }\n",
    "\n",
    "# Convert results to a DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(regression_results).T\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
